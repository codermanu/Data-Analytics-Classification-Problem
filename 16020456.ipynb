{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDrzLFXE8T1l"
   },
   "source": [
    "# Assignment 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jElLULrDhQZR"
   },
   "outputs": [],
   "source": [
    "import numpy as npy\n",
    "import pandas as pds\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfV2Dai0Ow2o"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4Wzg69bnwK2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built with TensorFlow version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Built with TensorFlow version: {}\".format(tsf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading 'data' from excel book using pandas\n",
    "xls   = pds.ExcelFile('IS4003_SCS4104_CS4104_dataset.xlsx')\n",
    "training_ds = pds.read_excel(xls, 'Training Dataset')\n",
    "testing_ds  = pds.read_excel(xls, 'Testing Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>ALK</th>\n",
       "      <th>SGPT</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>AG_Ratio</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>208</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>154</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>202</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>290</td>\n",
       "      <td>53</td>\n",
       "      <td>58</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Gender    TB   DB  ALK SGPT SGOT   TP  ALB AG_Ratio Class\n",
       "0   1   65  Female   0.7  0.1  187   16   18  6.8  3.3      0.9   Yes\n",
       "1   2   62    Male  10.9  5.5  699   64  100  7.5  3.2     0.74   Yes\n",
       "2   3   62    Male   7.3  4.1  490   60   68    7  3.3     0.89   Yes\n",
       "3   4   58    Male     1  0.4  182   14   20  6.8  3.4        1   Yes\n",
       "4   5   72    Male   3.9    2  195   27   59  7.3  2.4      0.4   Yes\n",
       "5   6   46    Male   1.8  0.7  208   19   14  7.6  4.4      1.3   Yes\n",
       "6   7   26  Female   0.9  0.2  154   16   12    7  3.5        1   Yes\n",
       "7   8   29  Female   0.9  0.3  202   14   11  6.7  3.6      1.1   Yes\n",
       "8   9   17    Male   0.9  0.3  202   22   19  7.4  4.1      1.2    No\n",
       "9  10   55    Male   0.7  0.2  290   53   58  6.8  3.4        1   Yes"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete 'ID' column \n",
    "del training_ds['ID']\n",
    "del testing_ds['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Age', 'Gender', 'TB', 'DB', 'ALK', 'SGPT', 'SGOT', 'TP', 'ALB', 'AG_Ratio']\n",
      "Label: Class\n"
     ]
    }
   ],
   "source": [
    "#Identify features and labels\n",
    "column_names = ['Age','Gender','TB','DB','ALK','SGPT','SGOT','TP','ALB','AG_Ratio','Class']\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))\n",
    "\n",
    "class_names= ['Yes', 'No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace \"?\" mark data with NaN values\n",
    "training_ds.replace('?', npy.NaN, inplace=True)\n",
    "testing_ds.replace('?', npy.NaN, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Gender    TB    DB   ALK  SGPT  SGOT    TP   ALB  AG_Ratio  Class\n",
      "0    True    True  True  True  True  True  True  True  True      True   True\n",
      "1    True    True  True  True  True  True  True  True  True      True   True\n",
      "2    True    True  True  True  True  True  True  True  True      True   True\n",
      "3    True    True  True  True  True  True  True  True  True      True   True\n",
      "4    True    True  True  True  True  True  True  True  True      True   True\n",
      "..    ...     ...   ...   ...   ...   ...   ...   ...   ...       ...    ...\n",
      "578  True    True  True  True  True  True  True  True  True      True   True\n",
      "579  True    True  True  True  True  True  True  True  True      True   True\n",
      "580  True    True  True  True  True  True  True  True  True      True   True\n",
      "581  True    True  True  True  True  True  True  True  True      True   True\n",
      "582  True    True  True  True  True  True  True  True  True      True   True\n",
      "\n",
      "[583 rows x 11 columns]\n",
      "      Age  Gender    TB    DB   ALK  SGPT  SGOT    TP   ALB  AG_Ratio  Class\n",
      "0    True    True  True  True  True  True  True  True  True      True   True\n",
      "1    True    True  True  True  True  True  True  True  True      True   True\n",
      "2    True    True  True  True  True  True  True  True  True      True   True\n",
      "3    True    True  True  True  True  True  True  True  True      True   True\n",
      "4    True    True  True  True  True  True  True  True  True      True   True\n",
      "..    ...     ...   ...   ...   ...   ...   ...   ...   ...       ...    ...\n",
      "306  True    True  True  True  True  True  True  True  True      True   True\n",
      "307  True    True  True  True  True  True  True  True  True      True   True\n",
      "308  True    True  True  True  True  True  True  True  True      True   True\n",
      "309  True    True  True  True  True  True  True  True  True      True   True\n",
      "310  True    True  True  True  True  True  True  True  True      True   True\n",
      "\n",
      "[311 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#Check the availability of \"?\" mark data\n",
    "print (training_ds.astype(str) != '?')\n",
    "print (testing_ds.astype(str) != '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for NaN values of data frame\n",
    "training_ds.isnull().values.any()\n",
    "testing_ds.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          45.372990\n",
       "TB            3.836482\n",
       "DB            1.726299\n",
       "ALK         277.812298\n",
       "SGPT         77.844156\n",
       "SGOT        103.734628\n",
       "TP            6.634516\n",
       "ALB           3.199032\n",
       "AG_Ratio      0.937735\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds.mean()\n",
    "testing_ds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN value with mean value\n",
    "training_ds.fillna(training_ds.mean(),inplace=True)\n",
    "testing_ds.fillna(testing_ds.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for NaN values of data frame\n",
    "training_ds.isnull().values.any()\n",
    "testing_ds.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Categorical Data Into Numeric Data\n",
    "# Using OneHotEncoding\n",
    "gender_training_ds = pds.get_dummies(training_ds, columns=['Gender'], drop_first=True)\n",
    "gender_testing_ds = pds.get_dummies(testing_ds, columns=['Gender'], drop_first=True)\n",
    "class_training_ds = pds.get_dummies(gender_training_ds, columns=['Class'], drop_first=True)\n",
    "class_testing_ds = pds.get_dummies(gender_testing_ds, columns=['Class'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>ALK</th>\n",
       "      <th>SGPT</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>AG_Ratio</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Class_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>208.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>154.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>202.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>202.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>290.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age    TB   DB    ALK  SGPT   SGOT   TP  ALB  AG_Ratio  Gender_Male  \\\n",
       "0   65   0.7  0.1  187.0  16.0   18.0  6.8  3.3      0.90            0   \n",
       "1   62  10.9  5.5  699.0  64.0  100.0  7.5  3.2      0.74            1   \n",
       "2   62   7.3  4.1  490.0  60.0   68.0  7.0  3.3      0.89            1   \n",
       "3   58   1.0  0.4  182.0  14.0   20.0  6.8  3.4      1.00            1   \n",
       "4   72   3.9  2.0  195.0  27.0   59.0  7.3  2.4      0.40            1   \n",
       "5   46   1.8  0.7  208.0  19.0   14.0  7.6  4.4      1.30            1   \n",
       "6   26   0.9  0.2  154.0  16.0   12.0  7.0  3.5      1.00            0   \n",
       "7   29   0.9  0.3  202.0  14.0   11.0  6.7  3.6      1.10            0   \n",
       "8   17   0.9  0.3  202.0  22.0   19.0  7.4  4.1      1.20            1   \n",
       "9   55   0.7  0.2  290.0  53.0   58.0  6.8  3.4      1.00            1   \n",
       "\n",
       "   Class_Yes  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  \n",
       "8          0  \n",
       "9          1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_training_ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>ALK</th>\n",
       "      <th>SGPT</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>AG_Ratio</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Class_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age    TB   DB    ALK  SGPT   SGOT   TP  ALB  AG_Ratio  Gender_Male  \\\n",
       "0   65   0.7  0.1  187.0  16.0   18.0  6.8  3.3      0.90            0   \n",
       "1   62  10.9  5.5  699.0  64.0  100.0  7.5  3.2      0.74            1   \n",
       "2   62   7.3  4.1  490.0  60.0   68.0  7.0  3.3      0.89            1   \n",
       "3   58   1.0  0.4  182.0  14.0   20.0  6.8  3.4      1.00            1   \n",
       "4   72   3.9  2.0  195.0  27.0   59.0  7.3  2.4      0.40            1   \n",
       "\n",
       "   Class_Yes  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_training_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'Class' column\n",
    "train_y = class_training_ds.pop('Class_Yes')\n",
    "test_y= class_testing_ds.pop('Class_Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>TB</th>\n",
       "      <th>DB</th>\n",
       "      <th>ALK</th>\n",
       "      <th>SGPT</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>TP</th>\n",
       "      <th>ALB</th>\n",
       "      <th>AG_Ratio</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age    TB   DB    ALK  SGPT   SGOT   TP  ALB  AG_Ratio  Gender_Male\n",
       "0   65   0.7  0.1  187.0  16.0   18.0  6.8  3.3      0.90            0\n",
       "1   62  10.9  5.5  699.0  64.0  100.0  7.5  3.2      0.74            1\n",
       "2   62   7.3  4.1  490.0  60.0   68.0  7.0  3.3      0.89            1\n",
       "3   58   1.0  0.4  182.0  14.0   20.0  6.8  3.4      1.00            1\n",
       "4   72   3.9  2.0  195.0  27.0   59.0  7.3  2.4      0.40            1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_training_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter labels for train and test data sets and get them into an aray\n",
    "training_ds_labels = npy.array(train_y)\n",
    "testing_ds_labels = npy.array(test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W23DIMVPQEBt"
   },
   "source": [
    "### Create a model using Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model created with 3 layers each has 128, 30, and 20 nodes.\n",
    "# relu and sigmoid as activation functions\n",
    "# Optimizer: Adam , Loss function: binary cross entropy\n",
    "\n",
    "def create_model( output_bias=None):\n",
    "    my_model = tsf.keras.Sequential([\n",
    "      tsf.keras.layers.Dense(128, activation='relu', \n",
    "                            input_shape=(class_training_ds.shape[-1],)),\n",
    "      tsf.keras.layers.Dense(30, activation='relu'),\n",
    "      tsf.keras.layers.Dense(20, activation='relu'),\n",
    "      tsf.keras.layers.Dropout(0.5),\n",
    "      tsf.keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "    ])\n",
    "    \n",
    "    my_model.compile(\n",
    "      optimizer=('adam'),\n",
    "      loss=tsf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    return my_model\n",
    "\n",
    "#number of iterations\n",
    "#number of data for each step\n",
    "EPOCHS = 600    \n",
    "BATCH_SIZE = 32 \n",
    "\n",
    "my_model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wFKnhWCpDSS"
   },
   "source": [
    "### Using the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "583/583 [==============================] - 0s 310us/sample - loss: 5.2774 - acc: 0.6158\n",
      "Epoch 2/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 1.6086 - acc: 0.6312\n",
      "Epoch 3/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.6342 - acc: 0.6792\n",
      "Epoch 4/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.6002 - acc: 0.7136\n",
      "Epoch 5/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5834 - acc: 0.7136\n",
      "Epoch 6/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5956 - acc: 0.7118\n",
      "Epoch 7/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5704 - acc: 0.7136\n",
      "Epoch 8/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5817 - acc: 0.7136\n",
      "Epoch 9/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5780 - acc: 0.7136\n",
      "Epoch 10/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5686 - acc: 0.7136\n",
      "Epoch 11/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5709 - acc: 0.7136\n",
      "Epoch 12/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5634 - acc: 0.7136\n",
      "Epoch 13/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5711 - acc: 0.7136\n",
      "Epoch 14/600\n",
      "583/583 [==============================] - 0s 57us/sample - loss: 0.5684 - acc: 0.7136\n",
      "Epoch 15/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5734 - acc: 0.7118\n",
      "Epoch 16/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5713 - acc: 0.7136\n",
      "Epoch 17/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5698 - acc: 0.7136\n",
      "Epoch 18/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5730 - acc: 0.7118\n",
      "Epoch 19/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5709 - acc: 0.7136\n",
      "Epoch 20/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5688 - acc: 0.7118\n",
      "Epoch 21/600\n",
      "583/583 [==============================] - 0s 61us/sample - loss: 0.5647 - acc: 0.7136\n",
      "Epoch 22/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5584 - acc: 0.7136\n",
      "Epoch 23/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5641 - acc: 0.7136\n",
      "Epoch 24/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5699 - acc: 0.7101\n",
      "Epoch 25/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5709 - acc: 0.7136\n",
      "Epoch 26/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5703 - acc: 0.7136\n",
      "Epoch 27/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5664 - acc: 0.7153\n",
      "Epoch 28/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.5614 - acc: 0.7136\n",
      "Epoch 29/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5627 - acc: 0.7136\n",
      "Epoch 30/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5619 - acc: 0.7136\n",
      "Epoch 31/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5528 - acc: 0.7136\n",
      "Epoch 32/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5636 - acc: 0.7101\n",
      "Epoch 33/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5542 - acc: 0.7136\n",
      "Epoch 34/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5643 - acc: 0.7136\n",
      "Epoch 35/600\n",
      "583/583 [==============================] - 0s 57us/sample - loss: 0.5618 - acc: 0.7118\n",
      "Epoch 36/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5681 - acc: 0.7136\n",
      "Epoch 37/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5676 - acc: 0.7153\n",
      "Epoch 38/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5695 - acc: 0.7136\n",
      "Epoch 39/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5732 - acc: 0.7170\n",
      "Epoch 40/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5669 - acc: 0.7136\n",
      "Epoch 41/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5538 - acc: 0.7136\n",
      "Epoch 42/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5580 - acc: 0.7136\n",
      "Epoch 43/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5620 - acc: 0.7118\n",
      "Epoch 44/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5506 - acc: 0.7136\n",
      "Epoch 45/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5472 - acc: 0.7136\n",
      "Epoch 46/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5606 - acc: 0.7136\n",
      "Epoch 47/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5653 - acc: 0.7170\n",
      "Epoch 48/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5512 - acc: 0.7136\n",
      "Epoch 49/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5563 - acc: 0.7136\n",
      "Epoch 50/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5627 - acc: 0.7136\n",
      "Epoch 51/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5658 - acc: 0.7136\n",
      "Epoch 52/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5635 - acc: 0.7067\n",
      "Epoch 53/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5661 - acc: 0.7136\n",
      "Epoch 54/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5564 - acc: 0.7153\n",
      "Epoch 55/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5572 - acc: 0.7136\n",
      "Epoch 56/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5562 - acc: 0.7153\n",
      "Epoch 57/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5609 - acc: 0.7101\n",
      "Epoch 58/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5551 - acc: 0.7136\n",
      "Epoch 59/600\n",
      "583/583 [==============================] - 0s 57us/sample - loss: 0.5544 - acc: 0.7136\n",
      "Epoch 60/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5488 - acc: 0.7153\n",
      "Epoch 61/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5510 - acc: 0.7153\n",
      "Epoch 62/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5534 - acc: 0.7136\n",
      "Epoch 63/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5458 - acc: 0.7153\n",
      "Epoch 64/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5510 - acc: 0.7067\n",
      "Epoch 65/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5448 - acc: 0.7170\n",
      "Epoch 66/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5622 - acc: 0.7050\n",
      "Epoch 67/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5551 - acc: 0.7136\n",
      "Epoch 68/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.5499 - acc: 0.7136\n",
      "Epoch 69/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5526 - acc: 0.7136\n",
      "Epoch 70/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.5452 - acc: 0.7136\n",
      "Epoch 71/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5522 - acc: 0.7136\n",
      "Epoch 72/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5465 - acc: 0.7136\n",
      "Epoch 73/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5517 - acc: 0.7136\n",
      "Epoch 74/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5395 - acc: 0.7136\n",
      "Epoch 75/600\n",
      "583/583 [==============================] - 0s 89us/sample - loss: 0.5484 - acc: 0.7136\n",
      "Epoch 76/600\n",
      "583/583 [==============================] - 0s 82us/sample - loss: 0.5480 - acc: 0.7136\n",
      "Epoch 77/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5447 - acc: 0.7136\n",
      "Epoch 78/600\n",
      "583/583 [==============================] - 0s 80us/sample - loss: 0.5459 - acc: 0.7136\n",
      "Epoch 79/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.5435 - acc: 0.7136\n",
      "Epoch 80/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5406 - acc: 0.7136\n",
      "Epoch 81/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5456 - acc: 0.7136\n",
      "Epoch 82/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5433 - acc: 0.7136\n",
      "Epoch 83/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5398 - acc: 0.7136\n",
      "Epoch 84/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5385 - acc: 0.7136\n",
      "Epoch 85/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5410 - acc: 0.7136\n",
      "Epoch 86/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5455 - acc: 0.7136\n",
      "Epoch 87/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5445 - acc: 0.7136\n",
      "Epoch 88/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5282 - acc: 0.7136\n",
      "Epoch 89/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5380 - acc: 0.7136\n",
      "Epoch 90/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5354 - acc: 0.7136\n",
      "Epoch 91/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5372 - acc: 0.7136\n",
      "Epoch 92/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5480 - acc: 0.7136\n",
      "Epoch 93/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5246 - acc: 0.7136\n",
      "Epoch 94/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5358 - acc: 0.7136\n",
      "Epoch 95/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5435 - acc: 0.7136\n",
      "Epoch 96/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5294 - acc: 0.7136\n",
      "Epoch 97/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5371 - acc: 0.7136\n",
      "Epoch 98/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5302 - acc: 0.7118\n",
      "Epoch 99/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5372 - acc: 0.7136\n",
      "Epoch 100/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5185 - acc: 0.7136\n",
      "Epoch 101/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5300 - acc: 0.7136\n",
      "Epoch 102/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5361 - acc: 0.7136\n",
      "Epoch 103/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5358 - acc: 0.7136\n",
      "Epoch 104/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5334 - acc: 0.7136\n",
      "Epoch 105/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5338 - acc: 0.7136\n",
      "Epoch 106/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5361 - acc: 0.7136\n",
      "Epoch 107/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5190 - acc: 0.7136\n",
      "Epoch 108/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5360 - acc: 0.7136\n",
      "Epoch 109/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5181 - acc: 0.7136\n",
      "Epoch 110/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5334 - acc: 0.7136\n",
      "Epoch 111/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5313 - acc: 0.7136\n",
      "Epoch 112/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5168 - acc: 0.7136\n",
      "Epoch 113/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5489 - acc: 0.7136\n",
      "Epoch 114/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5436 - acc: 0.7136\n",
      "Epoch 115/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5270 - acc: 0.7136\n",
      "Epoch 116/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5320 - acc: 0.7136\n",
      "Epoch 117/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5371 - acc: 0.7136\n",
      "Epoch 118/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5224 - acc: 0.7136\n",
      "Epoch 119/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5222 - acc: 0.7136\n",
      "Epoch 120/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5264 - acc: 0.7136\n",
      "Epoch 121/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5278 - acc: 0.7136\n",
      "Epoch 122/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5251 - acc: 0.7136\n",
      "Epoch 123/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5186 - acc: 0.7136\n",
      "Epoch 124/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5123 - acc: 0.7136\n",
      "Epoch 125/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5193 - acc: 0.7136\n",
      "Epoch 126/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5184 - acc: 0.7136\n",
      "Epoch 127/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5256 - acc: 0.7136\n",
      "Epoch 128/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5431 - acc: 0.7136\n",
      "Epoch 129/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5323 - acc: 0.7136\n",
      "Epoch 130/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5442 - acc: 0.7136\n",
      "Epoch 131/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5173 - acc: 0.7136\n",
      "Epoch 132/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5142 - acc: 0.7136\n",
      "Epoch 133/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5098 - acc: 0.7136\n",
      "Epoch 134/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5106 - acc: 0.7136\n",
      "Epoch 135/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5231 - acc: 0.7136\n",
      "Epoch 136/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5188 - acc: 0.7136\n",
      "Epoch 137/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5264 - acc: 0.7136\n",
      "Epoch 138/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5302 - acc: 0.7136\n",
      "Epoch 139/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5191 - acc: 0.7136\n",
      "Epoch 140/600\n",
      "583/583 [==============================] - 0s 116us/sample - loss: 0.5200 - acc: 0.7136\n",
      "Epoch 141/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5171 - acc: 0.7136\n",
      "Epoch 142/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5042 - acc: 0.7136\n",
      "Epoch 143/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5286 - acc: 0.7136\n",
      "Epoch 144/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5405 - acc: 0.7136\n",
      "Epoch 145/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5037 - acc: 0.7118\n",
      "Epoch 146/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5204 - acc: 0.7136\n",
      "Epoch 147/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5251 - acc: 0.7136\n",
      "Epoch 148/600\n",
      "583/583 [==============================] - 0s 53us/sample - loss: 0.5177 - acc: 0.7136\n",
      "Epoch 149/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5030 - acc: 0.7136\n",
      "Epoch 150/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5066 - acc: 0.7136\n",
      "Epoch 151/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5187 - acc: 0.7136\n",
      "Epoch 152/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5151 - acc: 0.7136\n",
      "Epoch 153/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5015 - acc: 0.7136\n",
      "Epoch 154/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5111 - acc: 0.7136\n",
      "Epoch 155/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5192 - acc: 0.7136\n",
      "Epoch 156/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5214 - acc: 0.7136\n",
      "Epoch 157/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5175 - acc: 0.7136\n",
      "Epoch 158/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5273 - acc: 0.7136\n",
      "Epoch 159/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5156 - acc: 0.7136\n",
      "Epoch 160/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.4941 - acc: 0.7136\n",
      "Epoch 161/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5383 - acc: 0.7118\n",
      "Epoch 162/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5247 - acc: 0.7136\n",
      "Epoch 163/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5337 - acc: 0.7136\n",
      "Epoch 164/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5355 - acc: 0.7136\n",
      "Epoch 165/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5081 - acc: 0.7136\n",
      "Epoch 166/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5193 - acc: 0.7136\n",
      "Epoch 167/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4960 - acc: 0.7136\n",
      "Epoch 168/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5071 - acc: 0.7136\n",
      "Epoch 169/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5100 - acc: 0.7136\n",
      "Epoch 170/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5156 - acc: 0.7136\n",
      "Epoch 171/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5118 - acc: 0.7136\n",
      "Epoch 172/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5018 - acc: 0.7136\n",
      "Epoch 173/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5068 - acc: 0.7136\n",
      "Epoch 174/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5225 - acc: 0.7136\n",
      "Epoch 175/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5176 - acc: 0.7136\n",
      "Epoch 176/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5102 - acc: 0.7136\n",
      "Epoch 177/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5142 - acc: 0.7136\n",
      "Epoch 178/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4987 - acc: 0.7136\n",
      "Epoch 179/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4916 - acc: 0.7136\n",
      "Epoch 180/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5091 - acc: 0.7136\n",
      "Epoch 181/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.5258 - acc: 0.7136\n",
      "Epoch 182/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5255 - acc: 0.7136\n",
      "Epoch 183/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5111 - acc: 0.7136\n",
      "Epoch 184/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5193 - acc: 0.7136\n",
      "Epoch 185/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5065 - acc: 0.7136\n",
      "Epoch 186/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4959 - acc: 0.7136\n",
      "Epoch 187/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5200 - acc: 0.7136\n",
      "Epoch 188/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5669 - acc: 0.7136\n",
      "Epoch 189/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5603 - acc: 0.7136\n",
      "Epoch 190/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5218 - acc: 0.7136\n",
      "Epoch 191/600\n",
      "583/583 [==============================] - 0s 73us/sample - loss: 0.5136 - acc: 0.7136\n",
      "Epoch 192/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4921 - acc: 0.7136\n",
      "Epoch 193/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5135 - acc: 0.7136\n",
      "Epoch 194/600\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.5182 - acc: 0.7136\n",
      "Epoch 195/600\n",
      "583/583 [==============================] - 0s 80us/sample - loss: 0.5131 - acc: 0.7136\n",
      "Epoch 196/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.5157 - acc: 0.7136\n",
      "Epoch 197/600\n",
      "583/583 [==============================] - 0s 75us/sample - loss: 0.5242 - acc: 0.7136\n",
      "Epoch 198/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5107 - acc: 0.7136\n",
      "Epoch 199/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4919 - acc: 0.7136\n",
      "Epoch 200/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5185 - acc: 0.7136\n",
      "Epoch 201/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5077 - acc: 0.7136\n",
      "Epoch 202/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5246 - acc: 0.7136\n",
      "Epoch 203/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5136 - acc: 0.7136\n",
      "Epoch 204/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5162 - acc: 0.7136\n",
      "Epoch 205/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5095 - acc: 0.7136\n",
      "Epoch 206/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5093 - acc: 0.7136\n",
      "Epoch 207/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5087 - acc: 0.7136\n",
      "Epoch 208/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5209 - acc: 0.7136\n",
      "Epoch 209/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4933 - acc: 0.7136\n",
      "Epoch 210/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5055 - acc: 0.7136\n",
      "Epoch 211/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5167 - acc: 0.7136\n",
      "Epoch 212/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4955 - acc: 0.7136\n",
      "Epoch 213/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5029 - acc: 0.7136\n",
      "Epoch 214/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5100 - acc: 0.7136\n",
      "Epoch 215/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5050 - acc: 0.7136\n",
      "Epoch 216/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5098 - acc: 0.7136\n",
      "Epoch 217/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5089 - acc: 0.7136\n",
      "Epoch 218/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5008 - acc: 0.7136\n",
      "Epoch 219/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4965 - acc: 0.7136\n",
      "Epoch 220/600\n",
      "583/583 [==============================] - 0s 89us/sample - loss: 0.5239 - acc: 0.7136\n",
      "Epoch 221/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5068 - acc: 0.7136\n",
      "Epoch 222/600\n",
      "583/583 [==============================] - 0s 89us/sample - loss: 0.5278 - acc: 0.7136\n",
      "Epoch 223/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.5147 - acc: 0.7136\n",
      "Epoch 224/600\n",
      "583/583 [==============================] - 0s 84us/sample - loss: 0.4942 - acc: 0.7136\n",
      "Epoch 225/600\n",
      "583/583 [==============================] - 0s 75us/sample - loss: 0.4987 - acc: 0.7136\n",
      "Epoch 226/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5069 - acc: 0.7136\n",
      "Epoch 227/600\n",
      "583/583 [==============================] - 0s 82us/sample - loss: 0.5078 - acc: 0.7136\n",
      "Epoch 228/600\n",
      "583/583 [==============================] - 0s 84us/sample - loss: 0.4975 - acc: 0.7136\n",
      "Epoch 229/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5046 - acc: 0.7136\n",
      "Epoch 230/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.4883 - acc: 0.7136\n",
      "Epoch 231/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5020 - acc: 0.7136\n",
      "Epoch 232/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5158 - acc: 0.7136\n",
      "Epoch 233/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5111 - acc: 0.7136\n",
      "Epoch 234/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5011 - acc: 0.7136\n",
      "Epoch 235/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5036 - acc: 0.7136\n",
      "Epoch 236/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4960 - acc: 0.7136\n",
      "Epoch 237/600\n",
      "583/583 [==============================] - ETA: 0s - loss: 0.6656 - acc: 0.562 - 0s 87us/sample - loss: 0.5030 - acc: 0.7136\n",
      "Epoch 238/600\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.5029 - acc: 0.7136\n",
      "Epoch 239/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.5041 - acc: 0.7136\n",
      "Epoch 240/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4992 - acc: 0.7136\n",
      "Epoch 241/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.5095 - acc: 0.7118\n",
      "Epoch 242/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5027 - acc: 0.7136\n",
      "Epoch 243/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5227 - acc: 0.7118\n",
      "Epoch 244/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.5083 - acc: 0.7136\n",
      "Epoch 245/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4991 - acc: 0.7136\n",
      "Epoch 246/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5005 - acc: 0.7136\n",
      "Epoch 247/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5134 - acc: 0.7136\n",
      "Epoch 248/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4878 - acc: 0.7136\n",
      "Epoch 249/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.5069 - acc: 0.7136\n",
      "Epoch 250/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4967 - acc: 0.7136\n",
      "Epoch 251/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5040 - acc: 0.7136\n",
      "Epoch 252/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5027 - acc: 0.7136\n",
      "Epoch 253/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4977 - acc: 0.7136\n",
      "Epoch 254/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5022 - acc: 0.7136\n",
      "Epoch 255/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5025 - acc: 0.7136\n",
      "Epoch 256/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4884 - acc: 0.7136\n",
      "Epoch 257/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4958 - acc: 0.7136\n",
      "Epoch 258/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4987 - acc: 0.7136\n",
      "Epoch 259/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4954 - acc: 0.7136\n",
      "Epoch 260/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5078 - acc: 0.7136\n",
      "Epoch 261/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4991 - acc: 0.7136\n",
      "Epoch 262/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5078 - acc: 0.7136\n",
      "Epoch 263/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4907 - acc: 0.7136\n",
      "Epoch 264/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5149 - acc: 0.7136\n",
      "Epoch 265/600\n",
      "583/583 [==============================] - 0s 75us/sample - loss: 0.5053 - acc: 0.7136\n",
      "Epoch 266/600\n",
      "583/583 [==============================] - 0s 84us/sample - loss: 0.4947 - acc: 0.7136\n",
      "Epoch 267/600\n",
      "583/583 [==============================] - 0s 92us/sample - loss: 0.4924 - acc: 0.7136\n",
      "Epoch 268/600\n",
      "583/583 [==============================] - 0s 77us/sample - loss: 0.4974 - acc: 0.7136\n",
      "Epoch 269/600\n",
      "583/583 [==============================] - 0s 80us/sample - loss: 0.4912 - acc: 0.7136\n",
      "Epoch 270/600\n",
      "583/583 [==============================] - 0s 82us/sample - loss: 0.5094 - acc: 0.7136\n",
      "Epoch 271/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5018 - acc: 0.7136\n",
      "Epoch 272/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4916 - acc: 0.7136\n",
      "Epoch 273/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4867 - acc: 0.7136\n",
      "Epoch 274/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4869 - acc: 0.7136\n",
      "Epoch 275/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4929 - acc: 0.7136\n",
      "Epoch 276/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5055 - acc: 0.7136\n",
      "Epoch 277/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4965 - acc: 0.7136\n",
      "Epoch 278/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5001 - acc: 0.7136\n",
      "Epoch 279/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5008 - acc: 0.7136\n",
      "Epoch 280/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5047 - acc: 0.7136\n",
      "Epoch 281/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4915 - acc: 0.7136\n",
      "Epoch 282/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5028 - acc: 0.7136\n",
      "Epoch 283/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5087 - acc: 0.7136\n",
      "Epoch 284/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5301 - acc: 0.7136\n",
      "Epoch 285/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5074 - acc: 0.7136\n",
      "Epoch 286/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4880 - acc: 0.7136\n",
      "Epoch 287/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4982 - acc: 0.7136\n",
      "Epoch 288/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5036 - acc: 0.7136\n",
      "Epoch 289/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4888 - acc: 0.7136\n",
      "Epoch 290/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4864 - acc: 0.7136\n",
      "Epoch 291/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4970 - acc: 0.7136\n",
      "Epoch 292/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4839 - acc: 0.7136\n",
      "Epoch 293/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4894 - acc: 0.7136\n",
      "Epoch 294/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5021 - acc: 0.7136\n",
      "Epoch 295/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4779 - acc: 0.7136\n",
      "Epoch 296/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4888 - acc: 0.7136\n",
      "Epoch 297/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4894 - acc: 0.7136\n",
      "Epoch 298/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4926 - acc: 0.7136\n",
      "Epoch 299/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4986 - acc: 0.7136\n",
      "Epoch 300/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4863 - acc: 0.7136\n",
      "Epoch 301/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4927 - acc: 0.7136\n",
      "Epoch 302/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4811 - acc: 0.7136\n",
      "Epoch 303/600\n",
      "583/583 [==============================] - 0s 53us/sample - loss: 0.4951 - acc: 0.7136\n",
      "Epoch 304/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5235 - acc: 0.7136\n",
      "Epoch 305/600\n",
      "583/583 [==============================] - 0s 51us/sample - loss: 0.5010 - acc: 0.7136\n",
      "Epoch 306/600\n",
      "583/583 [==============================] - 0s 55us/sample - loss: 0.5037 - acc: 0.7118\n",
      "Epoch 307/600\n",
      "583/583 [==============================] - 0s 53us/sample - loss: 0.4999 - acc: 0.7136\n",
      "Epoch 308/600\n",
      "583/583 [==============================] - 0s 53us/sample - loss: 0.4890 - acc: 0.7136\n",
      "Epoch 309/600\n",
      "583/583 [==============================] - ETA: 0s - loss: 0.3941 - acc: 0.781 - 0s 65us/sample - loss: 0.4906 - acc: 0.7136\n",
      "Epoch 310/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4950 - acc: 0.7136\n",
      "Epoch 311/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4874 - acc: 0.7136\n",
      "Epoch 312/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5056 - acc: 0.7136\n",
      "Epoch 313/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4910 - acc: 0.7136\n",
      "Epoch 314/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4916 - acc: 0.7136\n",
      "Epoch 315/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5025 - acc: 0.7136\n",
      "Epoch 316/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4932 - acc: 0.7136\n",
      "Epoch 317/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4927 - acc: 0.7136\n",
      "Epoch 318/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5000 - acc: 0.7136\n",
      "Epoch 319/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4927 - acc: 0.7136\n",
      "Epoch 320/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4898 - acc: 0.7136\n",
      "Epoch 321/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4936 - acc: 0.7136\n",
      "Epoch 322/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4951 - acc: 0.7136\n",
      "Epoch 323/600\n",
      "583/583 [==============================] - 0s 69us/sample - loss: 0.5082 - acc: 0.7136\n",
      "Epoch 324/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4816 - acc: 0.7136\n",
      "Epoch 325/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5168 - acc: 0.7136\n",
      "Epoch 326/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4941 - acc: 0.7136\n",
      "Epoch 327/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4985 - acc: 0.7136\n",
      "Epoch 328/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5008 - acc: 0.7136\n",
      "Epoch 329/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4882 - acc: 0.7136\n",
      "Epoch 330/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4927 - acc: 0.7136\n",
      "Epoch 331/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4906 - acc: 0.7136\n",
      "Epoch 332/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5070 - acc: 0.7136\n",
      "Epoch 333/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.4839 - acc: 0.7136\n",
      "Epoch 334/600\n",
      "583/583 [==============================] - 0s 82us/sample - loss: 0.4772 - acc: 0.7136\n",
      "Epoch 335/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.4753 - acc: 0.7136\n",
      "Epoch 336/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4802 - acc: 0.7136\n",
      "Epoch 337/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4906 - acc: 0.7136\n",
      "Epoch 338/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4820 - acc: 0.7136\n",
      "Epoch 339/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4726 - acc: 0.7136\n",
      "Epoch 340/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4807 - acc: 0.7136\n",
      "Epoch 341/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4856 - acc: 0.7118\n",
      "Epoch 342/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4833 - acc: 0.7136\n",
      "Epoch 343/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4863 - acc: 0.7136\n",
      "Epoch 344/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4816 - acc: 0.7136\n",
      "Epoch 345/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4770 - acc: 0.7136\n",
      "Epoch 346/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4891 - acc: 0.7136\n",
      "Epoch 347/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5265 - acc: 0.7136\n",
      "Epoch 348/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5040 - acc: 0.7136\n",
      "Epoch 349/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.5043 - acc: 0.7136\n",
      "Epoch 350/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.5116 - acc: 0.7136\n",
      "Epoch 351/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4935 - acc: 0.7136\n",
      "Epoch 352/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4922 - acc: 0.7136\n",
      "Epoch 353/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4825 - acc: 0.7136\n",
      "Epoch 354/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4849 - acc: 0.7136\n",
      "Epoch 355/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4800 - acc: 0.7136\n",
      "Epoch 356/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5129 - acc: 0.7136\n",
      "Epoch 357/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4866 - acc: 0.7136\n",
      "Epoch 358/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4750 - acc: 0.7136\n",
      "Epoch 359/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4845 - acc: 0.7136\n",
      "Epoch 360/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4912 - acc: 0.7136\n",
      "Epoch 361/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5002 - acc: 0.7136\n",
      "Epoch 362/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4997 - acc: 0.7136\n",
      "Epoch 363/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4933 - acc: 0.7136\n",
      "Epoch 364/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4695 - acc: 0.7136\n",
      "Epoch 365/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4741 - acc: 0.7136\n",
      "Epoch 366/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4760 - acc: 0.7136\n",
      "Epoch 367/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4805 - acc: 0.7136\n",
      "Epoch 368/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4764 - acc: 0.7136\n",
      "Epoch 369/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4804 - acc: 0.7136\n",
      "Epoch 370/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4888 - acc: 0.7136\n",
      "Epoch 371/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4669 - acc: 0.7136\n",
      "Epoch 372/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4812 - acc: 0.7136\n",
      "Epoch 373/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4743 - acc: 0.7136\n",
      "Epoch 374/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4781 - acc: 0.7136\n",
      "Epoch 375/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4860 - acc: 0.7136\n",
      "Epoch 376/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4784 - acc: 0.7136\n",
      "Epoch 377/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4765 - acc: 0.7136\n",
      "Epoch 378/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4865 - acc: 0.7136\n",
      "Epoch 379/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4888 - acc: 0.7136\n",
      "Epoch 380/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.5061 - acc: 0.7136\n",
      "Epoch 381/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4846 - acc: 0.7136\n",
      "Epoch 382/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4858 - acc: 0.7136\n",
      "Epoch 383/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4857 - acc: 0.7136\n",
      "Epoch 384/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4890 - acc: 0.7136\n",
      "Epoch 385/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4804 - acc: 0.7136\n",
      "Epoch 386/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4755 - acc: 0.7136\n",
      "Epoch 387/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4872 - acc: 0.7136\n",
      "Epoch 388/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4704 - acc: 0.7136\n",
      "Epoch 389/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4800 - acc: 0.7136\n",
      "Epoch 390/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4727 - acc: 0.7136\n",
      "Epoch 391/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4734 - acc: 0.7136\n",
      "Epoch 392/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4904 - acc: 0.7136\n",
      "Epoch 393/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4807 - acc: 0.7136\n",
      "Epoch 394/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4883 - acc: 0.7136\n",
      "Epoch 395/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4925 - acc: 0.7136\n",
      "Epoch 396/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4840 - acc: 0.7136\n",
      "Epoch 397/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4842 - acc: 0.7136\n",
      "Epoch 398/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4711 - acc: 0.7136\n",
      "Epoch 399/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4650 - acc: 0.7136\n",
      "Epoch 400/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4714 - acc: 0.7136\n",
      "Epoch 401/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4830 - acc: 0.7136\n",
      "Epoch 402/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4709 - acc: 0.7136\n",
      "Epoch 403/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4717 - acc: 0.7136\n",
      "Epoch 404/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4718 - acc: 0.7187\n",
      "Epoch 405/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.5013 - acc: 0.7153\n",
      "Epoch 406/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4913 - acc: 0.7136\n",
      "Epoch 407/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4870 - acc: 0.7136\n",
      "Epoch 408/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4877 - acc: 0.7136\n",
      "Epoch 409/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4824 - acc: 0.7136\n",
      "Epoch 410/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4875 - acc: 0.7136\n",
      "Epoch 411/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4882 - acc: 0.7136\n",
      "Epoch 412/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4884 - acc: 0.7136\n",
      "Epoch 413/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4969 - acc: 0.7136\n",
      "Epoch 414/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4771 - acc: 0.7136\n",
      "Epoch 415/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4780 - acc: 0.7136\n",
      "Epoch 416/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4745 - acc: 0.7136\n",
      "Epoch 417/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4780 - acc: 0.7136\n",
      "Epoch 418/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4635 - acc: 0.7118\n",
      "Epoch 419/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4892 - acc: 0.7136\n",
      "Epoch 420/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4977 - acc: 0.7118\n",
      "Epoch 421/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4765 - acc: 0.7136\n",
      "Epoch 422/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4930 - acc: 0.7136\n",
      "Epoch 423/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4831 - acc: 0.7136\n",
      "Epoch 424/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4819 - acc: 0.7136\n",
      "Epoch 425/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4884 - acc: 0.7136\n",
      "Epoch 426/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4858 - acc: 0.7136\n",
      "Epoch 427/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4794 - acc: 0.7136\n",
      "Epoch 428/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4860 - acc: 0.7136\n",
      "Epoch 429/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4905 - acc: 0.7136\n",
      "Epoch 430/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4865 - acc: 0.7136\n",
      "Epoch 431/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4826 - acc: 0.7136\n",
      "Epoch 432/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4781 - acc: 0.7136\n",
      "Epoch 433/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4700 - acc: 0.7136\n",
      "Epoch 434/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4770 - acc: 0.7136\n",
      "Epoch 435/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4713 - acc: 0.7136\n",
      "Epoch 436/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4733 - acc: 0.7136\n",
      "Epoch 437/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4742 - acc: 0.7136\n",
      "Epoch 438/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4791 - acc: 0.7136\n",
      "Epoch 439/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4729 - acc: 0.7136\n",
      "Epoch 440/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4699 - acc: 0.7136\n",
      "Epoch 441/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4770 - acc: 0.7136\n",
      "Epoch 442/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4676 - acc: 0.7136\n",
      "Epoch 443/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4616 - acc: 0.7136\n",
      "Epoch 444/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4803 - acc: 0.7136\n",
      "Epoch 445/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4765 - acc: 0.7136\n",
      "Epoch 446/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4758 - acc: 0.7136\n",
      "Epoch 447/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4721 - acc: 0.7136\n",
      "Epoch 448/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4734 - acc: 0.7136\n",
      "Epoch 449/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4673 - acc: 0.7136\n",
      "Epoch 450/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4604 - acc: 0.7136\n",
      "Epoch 451/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4664 - acc: 0.7136\n",
      "Epoch 452/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4661 - acc: 0.7136\n",
      "Epoch 453/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4894 - acc: 0.7136\n",
      "Epoch 454/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4808 - acc: 0.7136\n",
      "Epoch 455/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4829 - acc: 0.7136\n",
      "Epoch 456/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4694 - acc: 0.7136\n",
      "Epoch 457/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4775 - acc: 0.7136\n",
      "Epoch 458/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4697 - acc: 0.7136\n",
      "Epoch 459/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4656 - acc: 0.7136\n",
      "Epoch 460/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4703 - acc: 0.7136\n",
      "Epoch 461/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4924 - acc: 0.7136\n",
      "Epoch 462/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.5026 - acc: 0.7136\n",
      "Epoch 463/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4834 - acc: 0.7136\n",
      "Epoch 464/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4760 - acc: 0.7136\n",
      "Epoch 465/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4721 - acc: 0.7118\n",
      "Epoch 466/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4701 - acc: 0.7136\n",
      "Epoch 467/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4554 - acc: 0.7136\n",
      "Epoch 468/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4710 - acc: 0.7136\n",
      "Epoch 469/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4761 - acc: 0.7136\n",
      "Epoch 470/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4720 - acc: 0.7136\n",
      "Epoch 471/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4679 - acc: 0.7136\n",
      "Epoch 472/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4775 - acc: 0.7136\n",
      "Epoch 473/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4592 - acc: 0.7136\n",
      "Epoch 474/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4675 - acc: 0.7136\n",
      "Epoch 475/600\n",
      "583/583 [==============================] - 0s 80us/sample - loss: 0.4968 - acc: 0.7136\n",
      "Epoch 476/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.4942 - acc: 0.7136\n",
      "Epoch 477/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.4601 - acc: 0.7136\n",
      "Epoch 478/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4524 - acc: 0.7136\n",
      "Epoch 479/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4704 - acc: 0.7136\n",
      "Epoch 480/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4605 - acc: 0.7136\n",
      "Epoch 481/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4548 - acc: 0.7136\n",
      "Epoch 482/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4493 - acc: 0.7136\n",
      "Epoch 483/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4587 - acc: 0.7136\n",
      "Epoch 484/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4582 - acc: 0.7136\n",
      "Epoch 485/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4694 - acc: 0.7136\n",
      "Epoch 486/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4681 - acc: 0.7101\n",
      "Epoch 487/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4634 - acc: 0.7136\n",
      "Epoch 488/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4571 - acc: 0.7136\n",
      "Epoch 489/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4819 - acc: 0.7136\n",
      "Epoch 490/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4599 - acc: 0.7136\n",
      "Epoch 491/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4737 - acc: 0.7153\n",
      "Epoch 492/600\n",
      "583/583 [==============================] - 0s 82us/sample - loss: 0.4612 - acc: 0.7101\n",
      "Epoch 493/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4544 - acc: 0.7170\n",
      "Epoch 494/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4642 - acc: 0.7136\n",
      "Epoch 495/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.4690 - acc: 0.7136\n",
      "Epoch 496/600\n",
      "583/583 [==============================] - 0s 82us/sample - loss: 0.4868 - acc: 0.7136\n",
      "Epoch 497/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4713 - acc: 0.7136\n",
      "Epoch 498/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4677 - acc: 0.7101\n",
      "Epoch 499/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4715 - acc: 0.7136\n",
      "Epoch 500/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4540 - acc: 0.7118\n",
      "Epoch 501/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4626 - acc: 0.7136\n",
      "Epoch 502/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4533 - acc: 0.7136\n",
      "Epoch 503/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4752 - acc: 0.7136\n",
      "Epoch 504/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4743 - acc: 0.7136\n",
      "Epoch 505/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4745 - acc: 0.7153\n",
      "Epoch 506/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4690 - acc: 0.7136\n",
      "Epoch 507/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4600 - acc: 0.7136\n",
      "Epoch 508/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4534 - acc: 0.7136\n",
      "Epoch 509/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4602 - acc: 0.7153\n",
      "Epoch 510/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4679 - acc: 0.7153\n",
      "Epoch 511/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4462 - acc: 0.7136\n",
      "Epoch 512/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4739 - acc: 0.7153\n",
      "Epoch 513/600\n",
      "583/583 [==============================] - 0s 75us/sample - loss: 0.4585 - acc: 0.7101\n",
      "Epoch 514/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4561 - acc: 0.7136\n",
      "Epoch 515/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4602 - acc: 0.7136\n",
      "Epoch 516/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4594 - acc: 0.7136\n",
      "Epoch 517/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4702 - acc: 0.7136\n",
      "Epoch 518/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4647 - acc: 0.7153\n",
      "Epoch 519/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4618 - acc: 0.7170\n",
      "Epoch 520/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4525 - acc: 0.7136\n",
      "Epoch 521/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.4432 - acc: 0.7136\n",
      "Epoch 522/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4499 - acc: 0.7170\n",
      "Epoch 523/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.4499 - acc: 0.7101\n",
      "Epoch 524/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4567 - acc: 0.7153\n",
      "Epoch 525/600\n",
      "583/583 [==============================] - 0s 77us/sample - loss: 0.4633 - acc: 0.7221\n",
      "Epoch 526/600\n",
      "583/583 [==============================] - 0s 77us/sample - loss: 0.4764 - acc: 0.7153\n",
      "Epoch 527/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.4774 - acc: 0.7153\n",
      "Epoch 528/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4692 - acc: 0.7153\n",
      "Epoch 529/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4642 - acc: 0.7153\n",
      "Epoch 530/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4655 - acc: 0.7118\n",
      "Epoch 531/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.4693 - acc: 0.7153\n",
      "Epoch 532/600\n",
      "583/583 [==============================] - 0s 56us/sample - loss: 0.4507 - acc: 0.7153\n",
      "Epoch 533/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4670 - acc: 0.7136\n",
      "Epoch 534/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4609 - acc: 0.7187\n",
      "Epoch 535/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4636 - acc: 0.7153\n",
      "Epoch 536/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4615 - acc: 0.7118\n",
      "Epoch 537/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4502 - acc: 0.7153\n",
      "Epoch 538/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4516 - acc: 0.7136\n",
      "Epoch 539/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4483 - acc: 0.7136\n",
      "Epoch 540/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4477 - acc: 0.7153\n",
      "Epoch 541/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4535 - acc: 0.7153\n",
      "Epoch 542/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4478 - acc: 0.7136\n",
      "Epoch 543/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4563 - acc: 0.7153\n",
      "Epoch 544/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4585 - acc: 0.7118\n",
      "Epoch 545/600\n",
      "583/583 [==============================] - 0s 58us/sample - loss: 0.4397 - acc: 0.7136\n",
      "Epoch 546/600\n",
      "583/583 [==============================] - 0s 80us/sample - loss: 0.4355 - acc: 0.7187\n",
      "Epoch 547/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4722 - acc: 0.7101\n",
      "Epoch 548/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4492 - acc: 0.7153\n",
      "Epoch 549/600\n",
      "583/583 [==============================] - 0s 80us/sample - loss: 0.4623 - acc: 0.7153\n",
      "Epoch 550/600\n",
      "583/583 [==============================] - 0s 77us/sample - loss: 0.4560 - acc: 0.7170\n",
      "Epoch 551/600\n",
      "583/583 [==============================] - 0s 77us/sample - loss: 0.4599 - acc: 0.7170\n",
      "Epoch 552/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4508 - acc: 0.7153\n",
      "Epoch 553/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4405 - acc: 0.7136\n",
      "Epoch 554/600\n",
      "583/583 [==============================] - 0s 84us/sample - loss: 0.4483 - acc: 0.7187\n",
      "Epoch 555/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4457 - acc: 0.7153\n",
      "Epoch 556/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4462 - acc: 0.7187\n",
      "Epoch 557/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4561 - acc: 0.7118\n",
      "Epoch 558/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4468 - acc: 0.7187\n",
      "Epoch 559/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4535 - acc: 0.7187\n",
      "Epoch 560/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4529 - acc: 0.7136\n",
      "Epoch 561/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.4404 - acc: 0.7153\n",
      "Epoch 562/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4682 - acc: 0.7118\n",
      "Epoch 563/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4606 - acc: 0.7187\n",
      "Epoch 564/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4344 - acc: 0.7153\n",
      "Epoch 565/600\n",
      "583/583 [==============================] - 0s 75us/sample - loss: 0.4533 - acc: 0.7118\n",
      "Epoch 566/600\n",
      "583/583 [==============================] - 0s 86us/sample - loss: 0.4574 - acc: 0.7221\n",
      "Epoch 567/600\n",
      "583/583 [==============================] - 0s 80us/sample - loss: 0.4503 - acc: 0.7153\n",
      "Epoch 568/600\n",
      "583/583 [==============================] - 0s 94us/sample - loss: 0.4509 - acc: 0.7136\n",
      "Epoch 569/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4555 - acc: 0.7136\n",
      "Epoch 570/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4486 - acc: 0.7170\n",
      "Epoch 571/600\n",
      "583/583 [==============================] - 0s 68us/sample - loss: 0.4493 - acc: 0.7204\n",
      "Epoch 572/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4364 - acc: 0.7256\n",
      "Epoch 573/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4465 - acc: 0.7204\n",
      "Epoch 574/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4720 - acc: 0.7221\n",
      "Epoch 575/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4546 - acc: 0.7153\n",
      "Epoch 576/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4640 - acc: 0.7187\n",
      "Epoch 577/600\n",
      "583/583 [==============================] - 0s 61us/sample - loss: 0.4491 - acc: 0.7238\n",
      "Epoch 578/600\n",
      "583/583 [==============================] - 0s 60us/sample - loss: 0.4476 - acc: 0.7204\n",
      "Epoch 579/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4579 - acc: 0.7238\n",
      "Epoch 580/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4319 - acc: 0.7136\n",
      "Epoch 581/600\n",
      "583/583 [==============================] - 0s 63us/sample - loss: 0.4324 - acc: 0.7238\n",
      "Epoch 582/600\n",
      "583/583 [==============================] - 0s 62us/sample - loss: 0.4578 - acc: 0.7204\n",
      "Epoch 583/600\n",
      "583/583 [==============================] - 0s 67us/sample - loss: 0.4365 - acc: 0.7187\n",
      "Epoch 584/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.4299 - acc: 0.7273\n",
      "Epoch 585/600\n",
      "583/583 [==============================] - 0s 82us/sample - loss: 0.4447 - acc: 0.7153\n",
      "Epoch 586/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4327 - acc: 0.7256\n",
      "Epoch 587/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4378 - acc: 0.7101\n",
      "Epoch 588/600\n",
      "583/583 [==============================] - 0s 72us/sample - loss: 0.4481 - acc: 0.7118\n",
      "Epoch 589/600\n",
      "583/583 [==============================] - 0s 87us/sample - loss: 0.4654 - acc: 0.7238\n",
      "Epoch 590/600\n",
      "583/583 [==============================] - 0s 77us/sample - loss: 0.4524 - acc: 0.7256\n",
      "Epoch 591/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4537 - acc: 0.7204\n",
      "Epoch 592/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4460 - acc: 0.7187\n",
      "Epoch 593/600\n",
      "583/583 [==============================] - 0s 70us/sample - loss: 0.4502 - acc: 0.7170\n",
      "Epoch 594/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4570 - acc: 0.7238\n",
      "Epoch 595/600\n",
      "583/583 [==============================] - 0s 79us/sample - loss: 0.4391 - acc: 0.7118\n",
      "Epoch 596/600\n",
      "583/583 [==============================] - 0s 77us/sample - loss: 0.4338 - acc: 0.7170\n",
      "Epoch 597/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4486 - acc: 0.7187\n",
      "Epoch 598/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4748 - acc: 0.7273\n",
      "Epoch 599/600\n",
      "583/583 [==============================] - 0s 74us/sample - loss: 0.4430 - acc: 0.7221\n",
      "Epoch 600/600\n",
      "583/583 [==============================] - 0s 65us/sample - loss: 0.4608 - acc: 0.7118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b33383d648>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " my_model.fit(class_training_ds,\n",
    "          training_ds_labels,\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================] - 0s 115us/sample - loss: 0.4347 - acc: 0.7307\n",
      "Loss: 0.4347 Accuracy: 0.7307\n"
     ]
    }
   ],
   "source": [
    "results = my_model.evaluate(class_training_ds, training_ds_labels)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]), \"Accuracy: {:0.4f}\".format(results[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5142784 ],\n",
       "       [0.99949074],\n",
       "       [0.99789083],\n",
       "       [0.5195374 ],\n",
       "       [0.99999666],\n",
       "       [0.6252624 ],\n",
       "       [0.5513109 ],\n",
       "       [0.64236134],\n",
       "       [0.52876127],\n",
       "       [0.824805  ],\n",
       "       [0.53712463],\n",
       "       [0.9986952 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(class_training_ds[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 0s 90us/sample - loss: 0.4234 - acc: 0.7235\n",
      "Loss: 0.4234 Accuracy: 0.7235\n"
     ]
    }
   ],
   "source": [
    "results = my_model.evaluate(class_testing_ds, testing_ds_labels)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]), \"Accuracy: {:0.4f}\".format(results[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "train_predictions = my_model.predict(class_training_ds)\n",
    "test_predictions = my_model.predict(class_testing_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 60.0, 'Predicted Values')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Confutsion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sbn\n",
    "cm = confusion_matrix(testing_ds_labels, test_predictions >0.5)\n",
    "plt.figure(figsize=(9,9))\n",
    "sbn.heatmap(cm, annot=True, fmt=\"d\", cmap= \"Purples\")\n",
    "plt.title('Confusion Matrix'.format(0.5))\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.09        90\n",
      "           1       0.72      1.00      0.84       221\n",
      "\n",
      "    accuracy                           0.72       311\n",
      "   macro avg       0.86      0.52      0.46       311\n",
      "weighted avg       0.80      0.72      0.62       311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(testing_ds_labels,test_predictions>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7234726688102894\n"
     ]
    }
   ],
   "source": [
    "#Get Accuracy value\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(testing_ds_labels,test_predictions>0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "custom_training_walkthrough.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
